{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fecd95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76440e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset features:\n",
      "{'story': Value('string'), 'topic': Value('string'), 'theme': Value('string'), 'style': Value('string'), 'feature': Value('string'), 'grammar': Value('string'), 'persona': Value('string'), 'initial_word_type': Value('string'), 'initial_letter': Value('string'), 'word_count': Value('int64'), 'character_count': Value('int64'), 'num_paragraphs': Value('int64'), 'avg_word_length': Value('float64'), 'avg_sentence_length': Value('float64'), 'flesch_reading_ease': Value('float64'), 'flesch_kincaid_grade': Value('float64'), 'dale_chall_readability_score': Value('float64'), 'num_stories_in_completion': Value('int64'), 'expected_num_stories_in_completion': Value('int64'), 'generation_id': Value('string'), 'model': Value('string')}\n",
      "\n",
      "Dataset size: 2115696\n",
      "\n",
      "First example keys: ['story', 'topic', 'theme', 'style', 'feature', 'grammar', 'persona', 'initial_word_type', 'initial_letter', 'word_count', 'character_count', 'num_paragraphs', 'avg_word_length', 'avg_sentence_length', 'flesch_reading_ease', 'flesch_kincaid_grade', 'dale_chall_readability_score', 'num_stories_in_completion', 'expected_num_stories_in_completion', 'generation_id', 'model']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), '..'))\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ds = load_dataset(\"SimpleStories/SimpleStories\", split=\"train\")\n",
    "print(\"Dataset features:\")\n",
    "print(ds.features)\n",
    "print(f\"\\nDataset size: {len(ds)}\")\n",
    "print(f\"\\nFirst example keys: {list(ds[0].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1abdd",
   "metadata": {},
   "source": [
    "## Step 1: Explore Dataset and Generate Leaf Nodes\n",
    "\n",
    "First, we explore the dataset to propose 50 leaf nodes based on the dataset features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d6317df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 50000 examples from 2115696 total examples...\n",
      "\n",
      "Most common categorical values:\n",
      "\n",
      "topic (48 unique):\n",
      "  hidden treasures: 1123\n",
      "  magical lands: 1105\n",
      "  bygone eras: 1094\n",
      "  the arts: 1092\n",
      "  cultural traditions: 1086\n",
      "  seasonal changes: 1080\n",
      "  giant creatures: 1079\n",
      "  mystical creatures: 1076\n",
      "  time travel: 1073\n",
      "  lost civilizations: 1073\n",
      "\n",
      "theme (63 unique):\n",
      "  Magic: 878\n",
      "  Deception: 853\n",
      "  Helping Others: 852\n",
      "  Agency: 847\n",
      "  Innovation: 840\n",
      "  Kindness: 831\n",
      "  Problem-Solving: 827\n",
      "  Humor: 819\n",
      "  Growth: 817\n",
      "  Hardship: 814\n",
      "\n",
      "style (23 unique):\n",
      "  minimalist: 2325\n",
      "  classic: 2255\n",
      "  lighthearted: 2216\n",
      "  playful: 2215\n",
      "  modern: 2209\n",
      "  surreal: 2208\n",
      "  philosophical: 2199\n",
      "  humorous: 2181\n",
      "  tragic: 2180\n",
      "  fable-like: 2180\n",
      "\n",
      "feature (26 unique):\n",
      "  a flashback: 2021\n",
      "  circular narrative structure: 2013\n",
      "  a cliffhanger: 1994\n",
      "  a Red Herring: 1986\n",
      "  juxtaposition: 1981\n",
      "  a story within a story: 1961\n",
      "  Checkhov's gun: 1958\n",
      "  a moral lesson: 1950\n",
      "  absence indicating a presence: 1949\n",
      "  symbolism: 1939\n",
      "\n",
      "grammar (31 unique):\n",
      "  conditional mood: 862\n",
      "  wh-questions: 850\n",
      "  superlative forms: 850\n",
      "  discourse markers: 835\n",
      "  perfect aspect: 833\n",
      "  future tense: 831\n",
      "  non-finite clauses: 828\n",
      "  yes-no questions: 826\n",
      "  determiners: 824\n",
      "  indirect speech: 823\n",
      "\n",
      "persona (23 unique):\n",
      "  an academic: 595\n",
      "  an innocent author: 578\n",
      "  a jester archetype: 570\n",
      "  the oppressed: 567\n",
      "  a father: 561\n",
      "  someone curious: 561\n",
      "  a pedant: 560\n",
      "  someone who wants to prove a point: 559\n",
      "  a moralistic teacher: 557\n",
      "  a mother: 552\n",
      "\n",
      "initial_word_type (4 unique):\n",
      "  adverb: 12578\n",
      "  noun: 12557\n",
      "  preposition: 12470\n",
      "  adjective: 12395\n",
      "\n",
      "initial_letter (24 unique):\n",
      "  T: 7814\n",
      "  A: 6130\n",
      "  O: 3968\n",
      "  I: 3572\n",
      "  S: 3313\n",
      "  W: 2963\n",
      "  C: 2441\n",
      "  M: 2239\n",
      "  B: 2091\n",
      "  P: 2050\n",
      "\n",
      "\n",
      "Numeric feature statistics:\n",
      "\n",
      "word_count:\n",
      "  min=58.00, q25=160.00, median=255.00, q75=375.00, max=798.00\n",
      "\n",
      "character_count:\n",
      "  min=252.00, q25=733.00, median=1147.00, q75=1669.00, max=3857.00\n",
      "\n",
      "num_paragraphs:\n",
      "  min=1.00, q25=3.00, median=4.00, q75=6.00, max=9.00\n",
      "\n",
      "avg_word_length:\n",
      "  min=2.85, q25=3.57, median=3.71, q75=3.85, max=4.74\n",
      "\n",
      "avg_sentence_length:\n",
      "  min=5.67, q25=10.17, median=11.69, q75=13.38, max=38.40\n",
      "\n",
      "flesch_reading_ease:\n",
      "  min=57.37, q25=86.40, median=92.73, q75=96.08, max=108.70\n",
      "\n",
      "flesch_kincaid_grade:\n",
      "  min=-0.80, q25=2.20, median=3.00, q75=3.90, max=11.60\n",
      "\n",
      "dale_chall_readability_score:\n",
      "  min=0.92, q25=6.51, median=6.90, q75=7.35, max=10.22\n",
      "\n",
      "✓ Generated 50 leaf nodes\n",
      "\n",
      "First 10 leaf nodes:\n",
      " 1. topic-hidden-treasures: The story is about hidden treasures\n",
      " 2. topic-magical-lands: The story is about magical lands\n",
      " 3. topic-bygone-eras: The story is about bygone eras\n",
      " 4. topic-the-arts: The story is about the arts\n",
      " 5. topic-cultural-traditions: The story is about cultural traditions\n",
      " 6. topic-seasonal-changes: The story is about seasonal changes\n",
      " 7. topic-giant-creatures: The story is about giant creatures\n",
      " 8. topic-mystical-creatures: The story is about mystical creatures\n",
      " 9. topic-time-travel: The story is about time travel\n",
      "10. topic-lost-civilizations: The story is about lost civilizations\n"
     ]
    }
   ],
   "source": [
    "# Run the dataset exploration script\n",
    "from explore_dataset import explore_dataset, propose_leaf_nodes\n",
    "\n",
    "# Explore the dataset\n",
    "categorical_features, numeric_features = explore_dataset(sample_size=50000)\n",
    "\n",
    "# Propose leaf nodes\n",
    "leaf_nodes = propose_leaf_nodes(categorical_features, numeric_features)\n",
    "\n",
    "print(f\"\\n✓ Generated {len(leaf_nodes)} leaf nodes\")\n",
    "print(\"\\nFirst 10 leaf nodes:\")\n",
    "for i, node in enumerate(leaf_nodes[:10], 1):\n",
    "    print(f\"{i:2d}. {node['id']}: {node['description']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a6eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'proposed_leaf_nodes.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(leaf_nodes, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38522a93",
   "metadata": {},
   "source": [
    "## Step 2: Initialize Codebook Generator\n",
    "\n",
    "Set up the generator with OpenAI API (reads from environment variables or .env file).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6f97fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 leaf nodes\n"
     ]
    }
   ],
   "source": [
    "from generate_codebooks import CodebookGenerator\n",
    "generator = CodebookGenerator(model=\"gpt-5-mini-2025-08-07\")\n",
    "\n",
    "# Load the proposed leaf nodes\n",
    "leaf_nodes = generator.load_leaf_nodes(output_file)\n",
    "print(f\"Loaded {len(leaf_nodes)} leaf nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c88014",
   "metadata": {},
   "source": [
    "## Step 3: Generate a Test Codebook\n",
    "\n",
    "Generate a small test codebook to verify everything works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1f09aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Codebook:\n",
      "============================================================\n",
      "[TOPIC-MYSTICAL-CREATURES]\n",
      "A story is [TOPIC-MYSTICAL-CREATURES] if the story is about mystical creatures\n",
      "\n",
      "[TOPIC-THE-ARTS]\n",
      "A story is [TOPIC-THE-ARTS] if the story is about the arts\n",
      "\n",
      "[TOPIC-GIANT-CREATURES]\n",
      "A story is [TOPIC-GIANT-CREATURES] if the story is about giant creatures\n",
      "\n",
      "[TOPIC-BYGONE-ERAS]\n",
      "A story is [TOPIC-BYGONE-ERAS] if the story is about bygone eras\n",
      "\n",
      "[TOPIC-CULTURAL-TRADITIONS]\n",
      "A story is [TOPIC-CULTURAL-TRADITIONS] if the story is about cultural traditions\n",
      "\n",
      "[TOPIC-SEASONAL-CHANGES]\n",
      "A story is [TOPIC-SEASONAL-CHANGES] if the story is about seasonal changes\n",
      "\n",
      "[FANTASTICAL-HERITAGE]\n",
      "A story is [FANTASTICAL-HERITAGE] if either of the following is true:\n",
      "- The story is [TOPIC-MYSTICAL-CREATURES]\n",
      "- Both of the following are true:\n",
      "  - The story is [TOPIC-CULTURAL-TRADITIONS]\n",
      "  - The story is [TOPIC-BYGONE-ERAS]\n",
      "- Both of the following are true:\n",
      "  - The story is [TOPIC-THE-ARTS]\n",
      "  - The story is [TOPIC-SEASONAL-CHANGES]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate a small test codebook\n",
    "test_codebook = generator.generate_codebook(\n",
    "    leaf_nodes[:8],  # Use first 8 leaf nodes\n",
    "    size=\"small\",\n",
    "    difficulty=\"easy\",\n",
    "    use_all_formulas=False\n",
    ")\n",
    "\n",
    "print(\"Generated Codebook:\")\n",
    "print(\"=\" * 60)\n",
    "print(test_codebook)\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8a7e8a",
   "metadata": {},
   "source": [
    "## Step 4: Generate Obfuscated Version\n",
    "\n",
    "Create an obfuscated version where nodes are renamed to uninformative names (attr-1, attr-2, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f07000d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obfuscated Codebook:\n",
      "============================================================\n",
      "[attr-5]\n",
      "A story is [attr-5] if the story is about mystical creatures\n",
      "\n",
      "[attr-7]\n",
      "A story is [attr-7] if the story is about the arts\n",
      "\n",
      "[attr-4]\n",
      "A story is [attr-4] if the story is about giant creatures\n",
      "\n",
      "[attr-2]\n",
      "A story is [attr-2] if the story is about bygone eras\n",
      "\n",
      "[attr-3]\n",
      "A story is [attr-3] if the story is about cultural traditions\n",
      "\n",
      "[attr-6]\n",
      "A story is [attr-6] if the story is about seasonal changes\n",
      "\n",
      "[attr-1]\n",
      "A story is [attr-1] if either of the following is true:\n",
      "- The story is [attr-5]\n",
      "- Both of the following are true:\n",
      "  - The story is [attr-3]\n",
      "  - The story is [attr-2]\n",
      "- Both of the following are true:\n",
      "  - The story is [attr-7]\n",
      "  - The story is [attr-6]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate obfuscated version\n",
    "obfuscated_codebook = generator.obfuscate_codebook(test_codebook)\n",
    "\n",
    "print(\"Obfuscated Codebook:\")\n",
    "print(\"=\" * 60)\n",
    "print(obfuscated_codebook)\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e45c6",
   "metadata": {},
   "source": [
    "## Step 5: Generate Multiple Codebooks\n",
    "\n",
    "Generate codebooks of different sizes and difficulties. This will create:\n",
    "- 20 small codebooks (3-5 nodes)\n",
    "- 20 medium codebooks (6-10 nodes)  \n",
    "- 10 large codebooks (11-20 nodes)\n",
    "\n",
    "Each codebook will also have an obfuscated version saved as `-obfc.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d99284be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Small codebooks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Small codebooks: 100%|██████████| 1/1 [00:52<00:00, 52.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/test-1/cb-001-small-easy-allf.txt\n",
      "Saved: /home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/test-1/cb-001-small-easy-allf-obfc.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Medium codebooks: 100%|██████████| 1/1 [00:41<00:00, 41.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/test-1/cb-002-medium-medium-allf.txt\n",
      "Saved: /home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/test-1/cb-002-medium-medium-allf-obfc.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Large codebooks: 100%|██████████| 1/1 [01:04<00:00, 64.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/test-1/cb-003-large-hard-allf.txt\n",
      "Saved: /home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/test-1/cb-003-large-hard-allf-obfc.txt\n",
      "\n",
      "✓ Generated 3 codebooks (and obfuscated versions)\n",
      "  Output directory: /home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/test-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"test-1\"\n",
    "\n",
    "generator.generate_all_codebooks(\n",
    "    output_dir=output_dir,\n",
    "    small_count=1,\n",
    "    medium_count=1,\n",
    "    large_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aafb69",
   "metadata": {},
   "source": [
    "## Step 6: Generate Individual Codebooks\n",
    "\n",
    "Generate specific codebooks with custom parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc95ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium Codebook with All Formulas:\n",
      "============================================================\n",
      "[STYLE-LIGHTHEARTED]\n",
      "A story is STYLE-LIGHTHEARTED if the story is lighthearted.\n",
      "\n",
      "[THEME-HARDSHIP]\n",
      "A story is THEME-HARDSHIP if the story has the theme Hardship.\n",
      "\n",
      "[TOPIC-THE-ARTS]\n",
      "A story is TOPIC-THE-ARTS if the story is about the arts.\n",
      "\n",
      "[THEME-GROWTH]\n",
      "A story is THEME-GROWTH if the story has the theme Growth.\n",
      "\n",
      "[USES-WH-QUESTIONS]\n",
      "A story is USES-WH-QUESTIONS if the story uses wh-questions.\n",
      "\n",
      "[STARTS-WITH-ADVERB]\n",
      "A story is STARTS-WITH-ADVERB if the story starts with a adverb.\n",
      "\n",
      "[STYLE-CLASSIC]\n",
      "A story is STYLE-CLASSIC if the story is classic.\n",
      "\n",
      "[MOOD-XOR]\n",
      "A story is MOOD-XOR if exactly one of the following is true:\n",
      "- The story is [STYLE-LIGHTHEARTED]\n",
      "- The story is [STYLE-CLASSIC]\n",
      "\n",
      "[SERENE]\n",
      "A story is SERENE if both of the following are true:\n",
      "- The story is [STYLE-LIGHTHEARTED]\n",
      "- The story is not [THEME-HARDSHIP]\n",
      "\n",
      "[QUEST-OR-GROW]\n",
      "A story is QUEST-OR-GROW if either of the following are true:\n",
      "- The story is [USES-WH-QUESTIONS]\n",
      "- The story is [THEME-GROWTH]\n",
      "\n",
      "[ARTS-INCLUSIVE]\n",
      "A story is ARTS-INCLUSIVE if the story is in [TOPIC-THE-ARTS].\n",
      "\n",
      "[STYLE-EQUAL-START]\n",
      "A story is STYLE-EQUAL-START if the following equality holds:\n",
      "- The truth of [STYLE-CLASSIC] equals the truth of [STARTS-WITH-ADVERB].\n",
      "============================================================\n",
      "Saved: test-1/example-medium.txt\n",
      "Saved: test-1/example-medium-obfc.txt\n"
     ]
    }
   ],
   "source": [
    "medium_codebook = generator.generate_codebook(\n",
    "    leaf_nodes,\n",
    "    size=\"medium\",\n",
    "    difficulty=\"easy\",\n",
    "    use_all_formulas=True\n",
    ")\n",
    "\n",
    "print(\"Medium Codebook with All Formulas:\")\n",
    "print(\"=\" * 60)\n",
    "print(medium_codebook)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save it\n",
    "generator.save_codebook(medium_codebook, \"example-medium.txt\", output_dir=output_dir)\n",
    "\n",
    "# Generate and save obfuscated version\n",
    "obfuscated_medium = generator.obfuscate_codebook(medium_codebook)\n",
    "generator.save_codebook(obfuscated_medium, \"example-medium-obfc.txt\", output_dir=output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5558d7",
   "metadata": {},
   "source": [
    "## Step 7: Verify Generated Codebooks\n",
    "\n",
    "Parse a generated codebook to verify it's valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "193d7426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Error parsing codebook: In formula requires at least 2 arguments, got 1\n"
     ]
    }
   ],
   "source": [
    "test_codebook = medium_codebook\n",
    "\n",
    "from parser import CodebookParser\n",
    "\n",
    "parser = CodebookParser()\n",
    "\n",
    "test_file = Path(output_dir) / \"test-codebook.txt\"\n",
    "test_file.parent.mkdir(exist_ok=True)\n",
    "with open(test_file, 'w') as f:\n",
    "    f.write(test_codebook)\n",
    "\n",
    "try:\n",
    "    graph = parser.parse_codebook(str(test_file))\n",
    "    print(f\"✓ Successfully parsed codebook!\")\n",
    "    print(f\"  Nodes: {len(graph.nodes)}\")\n",
    "    print(f\"  Edges: {len(graph.edges)}\")\n",
    "    print(f\"\\nNodes:\")\n",
    "    for node in graph.nodes:\n",
    "        formula_type = type(node.formula).__name__ if node.formula else \"None\"\n",
    "        print(f\"  - {node.id}: {formula_type}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error parsing codebook: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbb720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
