{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5fecd95b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f90dfb1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = \"../2026-01-27\"\n",
        "test_output_dir = output_dir + \"_test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "76440e89",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jjb/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset features:\n",
            "{'story': Value('string'), 'topic': Value('string'), 'theme': Value('string'), 'style': Value('string'), 'feature': Value('string'), 'grammar': Value('string'), 'persona': Value('string'), 'initial_word_type': Value('string'), 'initial_letter': Value('string'), 'word_count': Value('int64'), 'character_count': Value('int64'), 'num_paragraphs': Value('int64'), 'avg_word_length': Value('float64'), 'avg_sentence_length': Value('float64'), 'flesch_reading_ease': Value('float64'), 'flesch_kincaid_grade': Value('float64'), 'dale_chall_readability_score': Value('float64'), 'num_stories_in_completion': Value('int64'), 'expected_num_stories_in_completion': Value('int64'), 'generation_id': Value('string'), 'model': Value('string')}\n",
            "\n",
            "Dataset size: 2115696\n",
            "\n",
            "First example keys: ['story', 'topic', 'theme', 'style', 'feature', 'grammar', 'persona', 'initial_word_type', 'initial_letter', 'word_count', 'character_count', 'num_paragraphs', 'avg_word_length', 'avg_sentence_length', 'flesch_reading_ease', 'flesch_kincaid_grade', 'dale_chall_readability_score', 'num_stories_in_completion', 'expected_num_stories_in_completion', 'generation_id', 'model']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), '..'))\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "ds = load_dataset(\"SimpleStories/SimpleStories\", split=\"train\")\n",
        "print(\"Dataset features:\")\n",
        "print(ds.features)\n",
        "print(f\"\\nDataset size: {len(ds)}\")\n",
        "print(f\"\\nFirst example keys: {list(ds[0].keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4d6317df",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing 50000 examples from 2115696 total examples...\n",
            "\n",
            "Most common categorical values:\n",
            "\n",
            "topic (48 unique):\n",
            "  hidden treasures: 1123\n",
            "  magical lands: 1105\n",
            "  bygone eras: 1094\n",
            "  the arts: 1092\n",
            "  cultural traditions: 1086\n",
            "  seasonal changes: 1080\n",
            "  giant creatures: 1079\n",
            "  mystical creatures: 1076\n",
            "  time travel: 1073\n",
            "  lost civilizations: 1073\n",
            "\n",
            "theme (63 unique):\n",
            "  Magic: 878\n",
            "  Deception: 853\n",
            "  Helping Others: 852\n",
            "  Agency: 847\n",
            "  Innovation: 840\n",
            "  Kindness: 831\n",
            "  Problem-Solving: 827\n",
            "  Humor: 819\n",
            "  Growth: 817\n",
            "  Hardship: 814\n",
            "\n",
            "style (23 unique):\n",
            "  minimalist: 2325\n",
            "  classic: 2255\n",
            "  lighthearted: 2216\n",
            "  playful: 2215\n",
            "  modern: 2209\n",
            "  surreal: 2208\n",
            "  philosophical: 2199\n",
            "  humorous: 2181\n",
            "  tragic: 2180\n",
            "  fable-like: 2180\n",
            "\n",
            "feature (26 unique):\n",
            "  a flashback: 2021\n",
            "  circular narrative structure: 2013\n",
            "  a cliffhanger: 1994\n",
            "  a Red Herring: 1986\n",
            "  juxtaposition: 1981\n",
            "  a story within a story: 1961\n",
            "  Checkhov's gun: 1958\n",
            "  a moral lesson: 1950\n",
            "  absence indicating a presence: 1949\n",
            "  symbolism: 1939\n",
            "\n",
            "grammar (31 unique):\n",
            "  conditional mood: 862\n",
            "  wh-questions: 850\n",
            "  superlative forms: 850\n",
            "  discourse markers: 835\n",
            "  perfect aspect: 833\n",
            "  future tense: 831\n",
            "  non-finite clauses: 828\n",
            "  yes-no questions: 826\n",
            "  determiners: 824\n",
            "  indirect speech: 823\n",
            "\n",
            "persona (23 unique):\n",
            "  an academic: 595\n",
            "  an innocent author: 578\n",
            "  a jester archetype: 570\n",
            "  the oppressed: 567\n",
            "  a father: 561\n",
            "  someone curious: 561\n",
            "  a pedant: 560\n",
            "  someone who wants to prove a point: 559\n",
            "  a moralistic teacher: 557\n",
            "  a mother: 552\n",
            "\n",
            "initial_word_type (4 unique):\n",
            "  adverb: 12578\n",
            "  noun: 12557\n",
            "  preposition: 12470\n",
            "  adjective: 12395\n",
            "\n",
            "initial_letter (24 unique):\n",
            "  T: 7814\n",
            "  A: 6130\n",
            "  O: 3968\n",
            "  I: 3572\n",
            "  S: 3313\n",
            "  W: 2963\n",
            "  C: 2441\n",
            "  M: 2239\n",
            "  B: 2091\n",
            "  P: 2050\n",
            "\n",
            "\n",
            "Numeric feature statistics:\n",
            "\n",
            "word_count:\n",
            "  min=58.00, q25=160.00, median=255.00, q75=375.00, max=798.00\n",
            "\n",
            "character_count:\n",
            "  min=252.00, q25=733.00, median=1147.00, q75=1669.00, max=3857.00\n",
            "\n",
            "num_paragraphs:\n",
            "  min=1.00, q25=3.00, median=4.00, q75=6.00, max=9.00\n",
            "\n",
            "avg_word_length:\n",
            "  min=2.85, q25=3.57, median=3.71, q75=3.85, max=4.74\n",
            "\n",
            "avg_sentence_length:\n",
            "  min=5.67, q25=10.17, median=11.69, q75=13.38, max=38.40\n",
            "\n",
            "flesch_reading_ease:\n",
            "  min=57.37, q25=86.40, median=92.73, q75=96.08, max=108.70\n",
            "\n",
            "flesch_kincaid_grade:\n",
            "  min=-0.80, q25=2.20, median=3.00, q75=3.90, max=11.60\n",
            "\n",
            "dale_chall_readability_score:\n",
            "  min=0.92, q25=6.51, median=6.90, q75=7.35, max=10.22\n",
            "\n",
            "✓ Generated 50 leaf nodes\n",
            "\n",
            "First 10 leaf nodes:\n",
            " 1. topic-hidden-treasures: The story is about hidden treasures\n",
            " 2. topic-magical-lands: The story is about magical lands\n",
            " 3. topic-bygone-eras: The story is about bygone eras\n",
            " 4. topic-the-arts: The story is about the arts\n",
            " 5. topic-cultural-traditions: The story is about cultural traditions\n",
            " 6. topic-seasonal-changes: The story is about seasonal changes\n",
            " 7. topic-giant-creatures: The story is about giant creatures\n",
            " 8. topic-mystical-creatures: The story is about mystical creatures\n",
            " 9. topic-time-travel: The story is about time travel\n",
            "10. topic-lost-civilizations: The story is about lost civilizations\n"
          ]
        }
      ],
      "source": [
        "# Run the dataset exploration script\n",
        "from explore_dataset import explore_dataset, propose_leaf_nodes\n",
        "\n",
        "# Explore the dataset\n",
        "categorical_features, numeric_features = explore_dataset(sample_size=50000)\n",
        "\n",
        "# Propose leaf nodes\n",
        "leaf_nodes = propose_leaf_nodes(categorical_features, numeric_features)\n",
        "\n",
        "print(f\"\\n✓ Generated {len(leaf_nodes)} leaf nodes\")\n",
        "print(\"\\nFirst 10 leaf nodes:\")\n",
        "for i, node in enumerate(leaf_nodes[:10], 1):\n",
        "    print(f\"{i:2d}. {node['id']}: {node['description']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a6eb5b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "output_file = 'proposed_leaf_nodes.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(leaf_nodes, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38522a93",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c6f97fcc",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'output_file' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m generator = CodebookGenerator(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-5-mini-2025-08-07\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the proposed leaf nodes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m leaf_nodes = generator.load_leaf_nodes(\u001b[43moutput_file\u001b[49m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(leaf_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m leaf nodes\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'output_file' is not defined"
          ]
        }
      ],
      "source": [
        "from generate_codebooks import CodebookGenerator\n",
        "generator = CodebookGenerator(model=\"gpt-5-mini-2025-08-07\")\n",
        "\n",
        "# Load the proposed leaf nodes\n",
        "leaf_nodes = generator.load_leaf_nodes(output_file)\n",
        "print(f\"Loaded {len(leaf_nodes)} leaf nodes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98c88014",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f09aae",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generate a small test codebook\n",
        "test_codebook = generator.generate_codebook(\n",
        "    leaf_nodes[:8],  # Use first 8 leaf nodes\n",
        "    size=\"small\",\n",
        "    difficulty=\"easy\",\n",
        "    use_all_formulas=False\n",
        ")\n",
        "\n",
        "print(\"Generated Codebook:\")\n",
        "print(\"=\" * 60)\n",
        "print(test_codebook)\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f8a7e8a",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f07000d6",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generate obfuscated version\n",
        "obfuscated_codebook = generator.obfuscate_codebook(test_codebook)\n",
        "\n",
        "print(\"Obfuscated Codebook:\")\n",
        "print(\"=\" * 60)\n",
        "print(obfuscated_codebook)\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae0e45c6",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d99284be",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "generator.generate_all_codebooks(\n",
        "    output_dir=output_dir,\n",
        "    small_count=20,\n",
        "    medium_count=15,\n",
        "    large_count=10,\n",
        "    insane_count=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62aafb69",
      "metadata": {},
      "source": [
        "## Step 6: Generate Individual Codebooks\n",
        "\n",
        "Generate specific codebooks with custom parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc95ccc2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "medium_codebook = generator.generate_codebook(\n",
        "    leaf_nodes,\n",
        "    size=\"medium\",\n",
        "    difficulty=\"easy\",\n",
        "    use_all_formulas=True\n",
        ")\n",
        "\n",
        "print(\"Medium Codebook with All Formulas:\")\n",
        "print(\"=\" * 60)\n",
        "print(medium_codebook)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Save it\n",
        "generator.save_codebook(medium_codebook, \"example-medium.txt\", output_dir=test_output_dir)\n",
        "\n",
        "# Generate and save obfuscated version\n",
        "obfuscated_medium = generator.obfuscate_codebook(medium_codebook)\n",
        "generator.save_codebook(obfuscated_medium, \"example-medium-obfc.txt\", output_dir=test_output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5558d7",
      "metadata": {},
      "source": [
        "## Step 7: Verify Generated Codebooks\n",
        "\n",
        "Parse a generated codebook to verify it's valid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "193d7426",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_codebook = medium_codebook\n",
        "\n",
        "from parser import CodebookParser\n",
        "\n",
        "parser = CodebookParser()\n",
        "\n",
        "test_file = Path(test_output_dir) / \"test-codebook.txt\"\n",
        "test_file.parent.mkdir(exist_ok=True)\n",
        "with open(test_file, 'w') as f:\n",
        "    f.write(test_codebook)\n",
        "\n",
        "try:\n",
        "    graph = parser.parse_codebook(str(test_file))\n",
        "    print(f\"✓ Successfully parsed codebook!\")\n",
        "    print(f\"  Nodes: {len(graph.nodes)}\")\n",
        "    print(f\"  Edges: {len(graph.edges)}\")\n",
        "    print(f\"\\nNodes:\")\n",
        "    for node in graph.nodes:\n",
        "        formula_type = type(node.formula).__name__ if node.formula else \"None\"\n",
        "        print(f\"  - {node.id}: {formula_type}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error parsing codebook: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "200fe9a9",
      "metadata": {},
      "source": [
        "## Step 8: Rewrite Codebooks in Different Styles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "29af05dd",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available styles:\n",
            "  - free-flow: Natural, conversational, flowing text that reads smoothly without rigid structure\n",
            "  - transcript: Dialogue-like, interview style with questions and answers, as if explaining to someone\n",
            "  - technical: Precise, formal technical language with clear definitions and specifications\n",
            "  - structured: Clear, organized format with bullet points, sections, and hierarchical organization\n",
            "  - flowery: Extended, descriptive, elaborate language with rich vocabulary and detailed explanations\n",
            "  - concise: Brief, to-the-point style with minimal words while maintaining clarity\n",
            "  - narrative: Story-like, engaging narrative style that weaves concepts together like a story\n"
          ]
        }
      ],
      "source": [
        "from rewrite_codebooks import CodebookRewriter\n",
        "\n",
        "rewriter = CodebookRewriter(model=\"gpt-5-mini-2025-08-07\")\n",
        "\n",
        "print(\"Available styles:\")\n",
        "for style in CodebookRewriter.STYLES:\n",
        "    print(f\"  - {style}: {CodebookRewriter.STYLE_DESCRIPTIONS[style]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c371fe5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_codebook_file = Path(test_output_dir) / \"test-codebook.txt\"\n",
        "\n",
        "if test_codebook_file.exists():\n",
        "    style = \"flowery\"\n",
        "    rewritten = rewriter.rewrite_codebook_file(str(test_codebook_file), style)\n",
        "    print(f\"✓ Rewritten in {style} style\")\n",
        "    print(f\"  Saved to: {rewritten}\")\n",
        "    \n",
        "    with open(rewritten, 'r') as f:\n",
        "        rewritten_text = f.read()\n",
        "    print(f\"\\nFirst 500 characters of {style} version:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(rewritten_text[:500])\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(f\"Test codebook not found at {test_codebook_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e80bfa9",
      "metadata": {},
      "source": [
        "# Step 9: Verify rewritten codebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4acc3271",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from parser import CodebookParser\n",
        "\n",
        "parser = CodebookParser()\n",
        "\n",
        "test_rewritten_file = Path(test_output_dir) / \"test-codebook-flowery.txt\"\n",
        "\n",
        "if test_rewritten_file.exists():\n",
        "    try:\n",
        "        graph = parser.parse_codebook(str(test_rewritten_file))\n",
        "        print(f\"✓ Successfully parsed rewritten codebook!\")\n",
        "        print(f\"  Nodes: {len(graph.nodes)}\")\n",
        "        print(f\"  Edges: {len(graph.edges)}\")\n",
        "        print(f\"\\nNodes (first 10):\")\n",
        "        for node in graph.nodes[:10]:\n",
        "            formula_type = type(node.formula).__name__ if node.formula else \"None\"\n",
        "            print(f\"  - {node.id}: {formula_type}\")\n",
        "        \n",
        "        # Compare with original\n",
        "        original_file = Path(test_output_dir) / \"test-codebook.txt\"\n",
        "        if original_file.exists():\n",
        "            original_graph = parser.parse_codebook(str(original_file))\n",
        "            print(f\"\\nComparison:\")\n",
        "            print(f\"  Original nodes: {len(original_graph.nodes)}\")\n",
        "            print(f\"  Rewritten nodes: {len(graph.nodes)}\")\n",
        "            print(f\"  Original edges: {len(original_graph.edges)}\")\n",
        "            print(f\"  Rewritten edges: {len(graph.edges)}\")\n",
        "            \n",
        "            # Check if node IDs match\n",
        "            original_ids = {node.id for node in original_graph.nodes}\n",
        "            rewritten_ids = {node.id for node in graph.nodes}\n",
        "            if original_ids == rewritten_ids:\n",
        "                print(f\"  ✓ All node IDs match!\")\n",
        "            else:\n",
        "                print(f\"  ⚠ Node ID mismatch!\")\n",
        "                print(f\"    Missing: {original_ids - rewritten_ids}\")\n",
        "                print(f\"    Extra: {rewritten_ids - original_ids}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error parsing rewritten codebook: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(f\"Rewritten codebook not found at {test_rewritten_file}\")\n",
        "    print(\"Run the rewriting step above first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2031407",
      "metadata": {},
      "source": [
        "## Step 10: Rewrite All Codebooks in Directory\n",
        "\n",
        "Rewrite all codebooks in a directory with all available styles. This will create multiple versions of each codebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ab3955c-4c92-4fed-810b-d087db9c52e0",
      "metadata": {},
      "source": [
        "## Complete Pipeline Script\n",
        "\n",
        "Use the `pipeline.py` script to run the entire process automatically:\n",
        "1. Generate codebooks\n",
        "2. Obfuscate originals\n",
        "3. Rewrite in different styles\n",
        "4. Obfuscate rewritten versions\n",
        "5. Parse and serialize all codebooks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "08066d87-9a33-407e-92fa-91f594a98c80",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CODEBOOK GENERATION PIPELINE\n",
            "================================================================================\n",
            "Output directory: /home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/../2026-01-27\n",
            "Rewriting styles: free-flow, transcript, technical, structured, flowery, concise, narrative\n",
            "\n",
            "Step 1: Generating codebooks...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Processed 55 codebooks\n",
            "  Skipped 55 existing original codebooks\n",
            "  Skipped 55 existing obfuscated codebooks\n",
            "  Output directory: /home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/../2026-01-27\n",
            "\n",
            "Step 2: Obfuscating original codebooks...\n",
            "--------------------------------------------------------------------------------\n",
            "Skipping 55 already obfuscated files.\n",
            "All original codebooks already obfuscated.\n",
            "\n",
            "Step 3: Rewriting codebooks in different styles...\n",
            "--------------------------------------------------------------------------------\n",
            "Skipping 385 already rewritten files.\n",
            "All codebooks already rewritten in all styles.\n",
            "\n",
            "Step 4: Obfuscating rewritten codebooks...\n",
            "--------------------------------------------------------------------------------\n",
            "Skipping 385 already obfuscated rewritten files.\n",
            "All rewritten codebooks already obfuscated.\n",
            "\n",
            "Step 5: Parsing and serializing all codebooks...\n",
            "--------------------------------------------------------------------------------\n",
            "Skipping 851 already parsed files.\n",
            "Parsing and serializing 29 codebook files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parsing codebooks: 100%|██████████| 29/29 [01:06<00:00,  2.30s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/api_utils.py\", line 34, in run_async\n",
            "    return asyncio.run(coro)\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jjb/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jjb/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
            "    return f.result()\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/../../parser/codebook_parser.py\", line 163, in parse_codebooks_parallel\n",
            "    raise RuntimeError(f\"Failed to parse {len(errors)} codebook(s):\\n\" + \"\\n\".join(error_messages[:5]))\n",
            "RuntimeError: Failed to parse 17 codebook(s):\n",
            "Failed to parse codebook 0: 'list' object has no attribute 'strip'\n",
            "Failed to parse codebook 1: Equal formula requires 2 arguments, got 1\n",
            "Failed to parse codebook 2: 'list' object has no attribute 'strip'\n",
            "Failed to parse codebook 3: 'list' object has no attribute 'strip'\n",
            "Failed to parse codebook 4: Equal formula requires 2 arguments, got 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/pipeline.py\", line 430, in _parse_and_serialize_all\n",
            "    graphs, graph_data_list = run_async(\n",
            "                              ^^^^^^^^^^\n",
            "  File \"/home/jjb/msc/axiom-guided-structured-reasoning/codebooks/generator/api_utils.py\", line 53, in run_async\n",
            "    return asyncio.run(coro)\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jjb/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jjb/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
            "    return f.result()\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "RuntimeError: cannot reuse already awaited coroutine\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Error during parallel parsing: cannot reuse already awaited coroutine\n",
            "Falling back to sequential parsing...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Initialize pipeline\u001b[39;00m\n\u001b[32m      5\u001b[39m pipeline = CodebookPipeline(\n\u001b[32m      6\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-5.2-2025-12-11\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;66;03m# \"gpt-5-mini-2025-08-07\",\u001b[39;00m\n\u001b[32m      7\u001b[39m     rewrite_styles=\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# None = all styles, or specify: [\"flowery\", \"technical\"]\u001b[39;00m\n\u001b[32m      8\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_full_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43msmall_count\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmedium_count\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlarge_count\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43minsane_count\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/codebooks/generator/pipeline.py:92\u001b[39m, in \u001b[36mCodebookPipeline.run_full_pipeline\u001b[39m\u001b[34m(self, output_dir, small_count, medium_count, large_count, insane_count)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStep 5: Parsing and serializing all codebooks...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_and_serialize_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStep 6: Visualizing all graphs...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/codebooks/generator/pipeline.py:474\u001b[39m, in \u001b[36mCodebookPipeline._parse_and_serialize_all\u001b[39m\u001b[34m(self, output_path)\u001b[39m\n\u001b[32m    472\u001b[39m     f = io.StringIO()\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m contextlib.redirect_stdout(f):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m         graph = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_codebook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcodebook_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m     successful += \u001b[32m1\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m parse_error:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/codebooks/generator/../../parser/codebook_parser.py:56\u001b[39m, in \u001b[36mCodebookParser.parse_codebook\u001b[39m\u001b[34m(self, codebook_path, output_path)\u001b[39m\n\u001b[32m     52\u001b[39m     codebook_text = f.read()\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: output_path = \u001b[38;5;28mself\u001b[39m._get_output_path(codebook_path)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m graph_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_graph_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcodebook_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m graph = \u001b[38;5;28mself\u001b[39m._create_graph_from_data(graph_data)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Save pickle file\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/codebooks/generator/../../parser/codebook_parser.py:74\u001b[39m, in \u001b[36mCodebookParser._extract_graph_structure\u001b[39m\u001b[34m(self, codebook_text)\u001b[39m\n\u001b[32m     71\u001b[39m prompt = \u001b[38;5;28mself\u001b[39m._create_extraction_prompt(codebook_text)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are an expert at analyzing codebooks and extracting logical graph structures. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     80\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou extract nodes, edges, and logical formulas from natural language descriptions.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     81\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Explicitly set to 1.0 (model default)\u001b[39;49;00m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson_object\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     result_text = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     92\u001b[39m     graph_data = json.loads(result_text)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/msc/axiom-guided-structured-reasoning/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Run the complete pipeline\n",
        "from pipeline import CodebookPipeline\n",
        "\n",
        "# Initialize pipeline\n",
        "pipeline = CodebookPipeline(\n",
        "    model=\"gpt-5.2-2025-12-11\", # \"gpt-5-mini-2025-08-07\",\n",
        "    rewrite_styles=None  # None = all styles, or specify: [\"flowery\", \"technical\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "pipeline.run_full_pipeline(\n",
        "    output_dir=output_dir,\n",
        "    small_count=20,\n",
        "    medium_count=20,\n",
        "    large_count=10,\n",
        "    insane_count=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08f661ec",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
